{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNHcC6wcF5IdAQyJDbzw7q4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OcBF9GGFQOah","executionInfo":{"status":"ok","timestamp":1707993425317,"user_tz":-330,"elapsed":1217,"user":{"displayName":"yasin khan","userId":"12173604934844843719"}},"outputId":"7d14d5d9-195c-47f6-c188-69c4ee0e0f3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 0.1607774466847678\n","Epoch 1000, Loss: 0.12456981735101422\n","Epoch 2000, Loss: 0.12254007857492107\n","Epoch 3000, Loss: 0.11201899962305015\n","Epoch 4000, Loss: 0.08843338931253787\n","Epoch 5000, Loss: 0.03156818572855254\n","Epoch 6000, Loss: 0.00873869013459478\n","Epoch 7000, Loss: 0.0042882195640496145\n","Epoch 8000, Loss: 0.00271410634120366\n","Epoch 9000, Loss: 0.0019481606825475584\n","\n","Predicted Output after Training:\n","[[0.05346295]\n"," [0.94765814]\n"," [0.94743188]\n"," [0.06062479]]\n"]}],"source":["import numpy as np\n","def sigmoid(x):\n"," return 1 / (1 + np.exp(-x))\n","def sigmoid_derivative(x):\n"," return x * (1 - x)\n","# Define the architecture of the neural network\n","input_size = 2\n","hidden_size = 3\n","output_size = 1\n","learning_rate = 0.1\n","# Initialize weights and biases\n","weights_input_hidden = np.random.rand(input_size, hidden_size)\n","biases_hidden = np.zeros((1, hidden_size))\n","weights_hidden_output = np.random.rand(hidden_size, output_size)\n","biases_output = np.zeros((1, output_size))\n","# Input data\n","X = np.array([[0, 0],\n"," [0, 1],\n"," [1, 0],\n"," [1, 1]])\n","# Target output\n","y = np.array([[0],\n"," [1],\n"," [1],\n"," [0]])\n","# Training the neural network using backpropagation\n","epochs = 10000\n","for epoch in range(epochs):\n"," # Forward pass\n"," hidden_layer_input = np.dot(X, weights_input_hidden) + biases_hidden\n"," hidden_layer_output = sigmoid(hidden_layer_input)\n"," output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n"," predicted_output = sigmoid(output_layer_input)\n"," # Calculate loss\n"," loss = 0.5 * np.mean((y - predicted_output) ** 2)\n"," # Backward pass (Backpropagation)\n"," output_error = y - predicted_output\n"," output_delta = output_error * sigmoid_derivative(predicted_output)\n"," hidden_layer_error = output_delta.dot(weights_hidden_output.T)\n"," hidden_layer_delta = hidden_layer_error * sigmoid_derivative(hidden_layer_output)\n"," # Update weights and biases\n"," weights_hidden_output += hidden_layer_output.T.dot(output_delta) * learning_rate\n"," biases_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n"," weights_input_hidden += X.T.dot(hidden_layer_delta) * learning_rate\n"," biases_hidden += np.sum(hidden_layer_delta, axis=0, keepdims=True) * learning_rate\n"," # Print the loss every 1000 epochs\n"," if epoch % 1000 == 0:\n","  print(f\"Epoch {epoch}, Loss: {loss}\")\n","# Test the trained neural network\n","test_input = np.array([[0, 0],\n"," [0, 1],\n"," [1, 0],\n"," [1, 1]])\n","hidden_layer_input_test = np.dot(test_input, weights_input_hidden) + biases_hidden\n","hidden_layer_output_test = sigmoid(hidden_layer_input_test)\n","output_layer_input_test = np.dot(hidden_layer_output_test, weights_hidden_output) +biases_output\n","predicted_output_test = sigmoid(output_layer_input_test)\n","print(\"\\nPredicted Output after Training:\")\n","print(predicted_output_test)\n"]}]}